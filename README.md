# RAG Chatbot with Haystack

A privacy-focused Retrieval-Augmented Generation (RAG) chatbot built with Haystack framework. Supports both cloud-based (OpenAI) and local LLM options (Ollama) for maximum data privacy.

## ğŸš€ Quick Start

### **Windows Users (Easiest!)**

**Just double-click:** `START.bat`

That's it! The menu system handles everything automatically.

### **Web Interface (Beautiful Dashboard!)**

**Launch RAPIDRAG web UI:**
```batch
start-webapp.bat              # Local access (you only)
start-webapp-network.bat      # Network access (team sharing)
start-webapp-external.bat     # External access (internet) âš ï¸
```

Features stunning space-themed interface with animations, chat, document upload, and analytics!

**Share with team:** Use network mode to allow LAN access!

### **Manual Setup (All Platforms)**

```bash
# 1. Install dependencies
pip install -r requirements.txt

# 2. Configure (interactive wizard)
python setup.py

# 3. Add knowledge base
python ingest_documents.py --samples

# 4. Start chatting!
python chatbot.py
```

**See:** [`docs/OUT_OF_BOX_GUIDE.md`](docs/OUT_OF_BOX_GUIDE.md) for zero-config setup!

---

## ğŸ“ Project Structure

```
RAG/
â”œâ”€â”€ ğŸ“„ Core Application
â”‚   â”œâ”€â”€ chatbot.py              # Interactive CLI chatbot
â”‚   â”œâ”€â”€ ingest_documents.py     # Document ingestion pipeline
â”‚   â”œâ”€â”€ rag_pipeline.py         # RAG query pipeline
â”‚   â”œâ”€â”€ config.py               # Configuration management
â”‚   â””â”€â”€ setup.py                # Interactive setup wizard
â”‚
â”œâ”€â”€ ğŸ“š Documentation
â”‚   â”œâ”€â”€ docs/
â”‚   â”‚   â”œâ”€â”€ README.md           # Main documentation
â”‚   â”‚   â”œâ”€â”€ PROJECT_OVERVIEW.md # Technical architecture
â”‚   â”‚   â”œâ”€â”€ GET_STARTED.txt     # Quick reference
â”‚   â”‚   â””â”€â”€ guides/
â”‚   â”‚       â”œâ”€â”€ QUICKSTART.md   # 5-minute guide
â”‚   â”‚       â””â”€â”€ PRIVACY.md      # Privacy & security
â”‚
â”œâ”€â”€ ğŸ§ª Tests
â”‚   â””â”€â”€ tests/
â”‚       â”œâ”€â”€ test_setup.py       # System verification
â”‚       â”œâ”€â”€ test_chat.py        # Quick Q&A test
â”‚       â””â”€â”€ compare_models.py   # OpenAI vs Ollama
â”‚
â”œâ”€â”€ ğŸ“‚ Data & Documents
â”‚   â”œâ”€â”€ documents/              # ğŸ‘ˆ PUT YOUR FILES HERE
â”‚   â”‚   â””â”€â”€ README.md           # Format guide
â”‚   â””â”€â”€ data/                   # Generated (auto-created)
â”‚       â””â”€â”€ document_store.json # Vector database
â”‚
â””â”€â”€ âš™ï¸ Configuration
    â”œâ”€â”€ .env                    # Your settings (not in git)
    â”œâ”€â”€ .env.example            # Configuration template
    â”œâ”€â”€ requirements.txt        # Python dependencies
    â””â”€â”€ .gitignore              # Git exclusions
```

---

## ğŸ“š Adding Your Knowledge Base

### Where to Put Files
**Place all documents in the `documents/` folder:**

```bash
documents/
â”œâ”€â”€ your-file.txt
â”œâ”€â”€ your-file.md
â”œâ”€â”€ your-file.pdf      # PDF support
â”œâ”€â”€ your-file.docx     # Word documents
â”œâ”€â”€ your-file.html     # HTML pages
â””â”€â”€ subfolder/
    â””â”€â”€ more-docs.txt  # Supports nested folders
```

### Supported Formats

| Format | Extension | Support |
|--------|-----------|---------|
| Plain Text | `.txt` | âœ… Full |
| Markdown | `.md` | âœ… Full |
| PDF | `.pdf` | âœ… Full |
| Word | `.docx` | âœ… Full |
| HTML | `.html`, `.htm` | âœ… Full |
| JSON | `.json` | âœ… Full |

### Ingest Your Documents

```bash
# Ingest all files from documents/ folder
python ingest_documents.py

# Or test with samples first
python ingest_documents.py --samples
```

---

## ğŸ”’ Privacy Options

### Maximum Privacy (Recommended)
**Use Ollama - 100% Local**
- All processing on your machine
- No external API calls
- No data leaves your infrastructure
- Free to use
- **Currently active!** âœ…

### Cloud Option
**Use OpenAI API**
- Faster responses
- Most capable model
- Requires API key
- Data sent to OpenAI servers

**Switch anytime:**
```bash
python switch_provider.py
```

Or edit `.env` file: `LLM_PROVIDER=ollama` or `LLM_PROVIDER=openai`

---

## ğŸ¯ Common Commands

### **Windows - Use Menu System (Recommended)**

```batch
# Launch menu system
rag-menu.bat

# Or quick launcher
START.bat
```

**Menu includes (16 options):**
- First-time setup (auto-install everything)
- Document ingestion
- Start chatbot (CLI)
- **Start web interface (3 modes: Local/Network/External)**
- System tests
- Provider switching
- Documentation viewer
- And more!

### **Manual Commands (All Platforms)**

```bash
# Start interactive chatbot
python chatbot.py

# Add documents to knowledge base
python ingest_documents.py

# Test system status
python tests/test_setup.py

# Quick Q&A test
python tests/test_chat.py

# Compare OpenAI vs Ollama
python tests/compare_models.py

# Switch between providers
python switch_provider.py

# Setup wizard
python setup.py
```

---

## ğŸ’¬ Using the Chatbot

Start the chatbot:
```bash
python chatbot.py
```

Available commands:
- Type your question and press Enter
- `help` - Show available commands
- `info` - Display system information
- `history` - Show conversation history
- `clear` - Clear conversation history
- `exit` or `quit` - Exit chatbot

---

## ğŸ—ï¸ Architecture

```
User Query â†’ Text Embedder (local) â†’ Retriever â†’ Documents
                                                      â†“
              LLM (Ollama/OpenAI) â† Prompt Builder â† Context
                                                      â†“
                                                   Answer
```

**Components:**
- **Document Store**: InMemoryDocumentStore (stores documents + embeddings)
- **Embedder**: SentenceTransformers (all-MiniLM-L6-v2) - runs locally
- **Retriever**: Semantic search using embeddings
- **Generator**: Ollama (llama3.2) or OpenAI GPT (configurable)

---

## ğŸ“– Documentation

- **Quick Start**: [`docs/GET_STARTED.txt`](docs/GET_STARTED.txt)
- **Full Guide**: [`docs/guides/QUICKSTART.md`](docs/guides/QUICKSTART.md)
- **Privacy**: [`docs/guides/PRIVACY.md`](docs/guides/PRIVACY.md)
- **Technical Details**: [`docs/PROJECT_OVERVIEW.md`](docs/PROJECT_OVERVIEW.md)

---

## ğŸ”§ Configuration

Edit `.env` to customize:
- `LLM_PROVIDER` - Choose "openai" or "ollama"
- `EMBEDDING_MODEL` - Change embedding model
- `TOP_K_RETRIEVAL` - Number of documents to retrieve (default: 3)
- Model-specific settings (API keys, URLs, etc.)

---

## ğŸ›¡ï¸ Security Best Practices

1. âœ… Never commit `.env` file (already in .gitignore)
2. âœ… For maximum privacy: Use Ollama (100% local)
3. âœ… API keys: Store in `.env`, never hardcode
4. âœ… Embeddings: Always run locally

---

## ğŸ“ Learn More

- [Haystack Documentation](https://haystack.deepset.ai/)
- [RAG Tutorial](https://haystack.deepset.ai/tutorials/27_first_rag_pipeline)
- [Ollama Models](https://ollama.ai/library)
- [Haystack Discord](https://discord.com/invite/xYvH6drSmA)

---

## ğŸ“Š System Status

âœ… **All packages installed**  
âœ… **Knowledge base ready** (4 sample documents)  
âœ… **OpenAI integration** (cloud, fast)  
âœ… **Ollama integration** (local, private, active)  
âœ… **Multi-format support** (TXT, MD, PDF, DOCX, HTML, JSON)  
âœ… **Complete documentation**

---

**Ready to build your knowledge base!** ğŸš€

Place your documents in `documents/` folder and run `python ingest_documents.py`
